{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:08.601516Z",
     "iopub.status.busy": "2025-02-08T19:40:08.601238Z",
     "iopub.status.idle": "2025-02-08T19:40:26.359353Z",
     "shell.execute_reply": "2025-02-08T19:40:26.358508Z",
     "shell.execute_reply.started": "2025-02-08T19:40:08.601494Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain langchain_groq langchain_community\n",
    "!pip install -qU duckduckgo-search arxiv wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:26.360541Z",
     "iopub.status.busy": "2025-02-08T19:40:26.360295Z",
     "iopub.status.idle": "2025-02-08T19:40:26.364460Z",
     "shell.execute_reply": "2025-02-08T19:40:26.363618Z",
     "shell.execute_reply.started": "2025-02-08T19:40:26.360519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:26.365573Z",
     "iopub.status.busy": "2025-02-08T19:40:26.365286Z",
     "iopub.status.idle": "2025-02-08T19:40:27.880664Z",
     "shell.execute_reply": "2025-02-08T19:40:27.879994Z",
     "shell.execute_reply.started": "2025-02-08T19:40:26.365544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"mixtral-8x7b-32768\",\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:27.881821Z",
     "iopub.status.busy": "2025-02-08T19:40:27.881473Z",
     "iopub.status.idle": "2025-02-08T19:40:27.886281Z",
     "shell.execute_reply": "2025-02-08T19:40:27.885348Z",
     "shell.execute_reply.started": "2025-02-08T19:40:27.881798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# The ReAct template for Mixtral Model\n",
    "react_template = \"\"\"\n",
    "<s>[INST] You are an AI assistant that answers questions by breaking them down and using tools precisely.\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "Previous conversation history:\n",
    "{chat_history}\n",
    "\n",
    "Use the following format STRICTLY and EXACTLY:\n",
    "Question: the input question you must answer  \n",
    "Thought: you should always think about what to do  \n",
    "Action: the action to take, should be one of [{tool_names}]  \n",
    "Action Input: the input to the action  \n",
    "Observation: the result of the action  \n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)  \n",
    "Thought: I now know the final answer  \n",
    "Final Answer: the final answer to the original input question  \n",
    "\n",
    "IMPORTANT: After providing the Final Answer, you must STOP. Do not generate any additional text or steps.\n",
    "IMPORTANT: If a tool result is bad, try another tool.\n",
    "IMPORTANT: Use the chat history to provide more contextual and consistent responses.\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad} [/INST]\n",
    "Thought: Let me break this down step by step and follow the format exactly...\n",
    "{agent_scratchpad}</s>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=react_template,\n",
    "    input_variables=[\"tools\", \"tool_names\", \"input\", \"agent_scratchpad\", \"chat_history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:27.888904Z",
     "iopub.status.busy": "2025-02-08T19:40:27.888682Z",
     "iopub.status.idle": "2025-02-08T19:40:28.759884Z",
     "shell.execute_reply": "2025-02-08T19:40:28.759024Z",
     "shell.execute_reply.started": "2025-02-08T19:40:27.888884Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, load_tools \n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:28.761456Z",
     "iopub.status.busy": "2025-02-08T19:40:28.761026Z",
     "iopub.status.idle": "2025-02-08T19:40:29.116162Z",
     "shell.execute_reply": "2025-02-08T19:40:29.115276Z",
     "shell.execute_reply.started": "2025-02-08T19:40:28.761422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='DuckDuckGoSearch', description='A web search engine. Use this to as a search engine for general queries.', func=<bound method BaseTool.run of DuckDuckGoSearchResults(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))>), Tool(name='Wikipedia Search Tool', description='An API search tool, use it to retrieve information from Wikipedia articles.', func=<bound method BaseTool.run of WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000))>), Tool(name='Arxiv Search Tool', description='An API search tool, use it to search for academic papers, preprints, and research articles on Arxiv.', func=<bound method BaseTool.run of ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000))>)]\n"
     ]
    }
   ],
   "source": [
    "duckduck = DuckDuckGoSearchResults()\n",
    "duckduck_tool = Tool(\n",
    "    name=\"DuckDuckGoSearch\",\n",
    "    description=\"A web search engine. Use this to as a search engine for general queries.\",\n",
    "    func=duckduck.run)\n",
    "\n",
    "wiki_wrapper = WikipediaAPIWrapper()\n",
    "wiki_query = WikipediaQueryRun(api_wrapper=wiki_wrapper)\n",
    "wiki_tool = Tool(\n",
    "    name=\"Wikipedia Search Tool\",\n",
    "    description=\"An API search tool, use it to retrieve information from Wikipedia articles.\",\n",
    "    func=wiki_query.run)\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper()\n",
    "arxiv_query = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv_tool = Tool(\n",
    "    name=\"Arxiv Search Tool\",\n",
    "    description=\"An API search tool, use it to search for academic papers, preprints, and research articles on Arxiv.\",\n",
    "    func=arxiv_query.run)\n",
    "\n",
    "tools = [duckduck_tool, wiki_tool, arxiv_tool]\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:29.117637Z",
     "iopub.status.busy": "2025-02-08T19:40:29.117109Z",
     "iopub.status.idle": "2025-02-08T19:40:29.122027Z",
     "shell.execute_reply": "2025-02-08T19:40:29.121020Z",
     "shell.execute_reply.started": "2025-02-08T19:40:29.117602Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-2190517d13ab>:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  buffer_memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "buffer_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:29.122888Z",
     "iopub.status.busy": "2025-02-08T19:40:29.122693Z",
     "iopub.status.idle": "2025-02-08T19:40:29.145411Z",
     "shell.execute_reply": "2025-02-08T19:40:29.144556Z",
     "shell.execute_reply.started": "2025-02-08T19:40:29.122870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor,create_react_agent\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Create the executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=buffer_memory,\n",
    "    verbose=False,\n",
    "    handle_parsing_errors=True,\n",
    "    return_intermediate_steps=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:29.146507Z",
     "iopub.status.busy": "2025-02-08T19:40:29.146295Z",
     "iopub.status.idle": "2025-02-08T19:40:29.159346Z",
     "shell.execute_reply": "2025-02-08T19:40:29.158702Z",
     "shell.execute_reply.started": "2025-02-08T19:40:29.146490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def chat_with_memory(question):\n",
    "    if \"clear memory\" in question.lower() or \"reset\" in question.lower():\n",
    "        buffer_memory.chat_memory.clear()\n",
    "        return \"Memory has been cleared!\"\n",
    "    \n",
    "    result = agent_executor.invoke(\n",
    "        {\n",
    "            \"input\": question,\n",
    "            \"chat_history\": buffer_memory.chat_memory.messages\n",
    "        }\n",
    "    )\n",
    "    return result[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-08T19:40:29.160386Z",
     "iopub.status.busy": "2025-02-08T19:40:29.160147Z",
     "iopub.status.idle": "2025-02-08T19:42:28.377760Z",
     "shell.execute_reply": "2025-02-08T19:42:28.376881Z",
     "shell.execute_reply.started": "2025-02-08T19:40:29.160356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am your assistant. You can start asking questions now.\n",
      "(Type 'exit' to end the chat.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  Hi, How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! I'm an AI assistant, and I'm here to help you with any questions you have. How can I assist you today?\n",
      "\n",
      "(Stop)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  who is the founder of spaceX?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Elon Musk is the founder of SpaceX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  when was he born?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Elon Musk was born on June 28, 1971.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  what other companies does he have?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Elon Musk is associated with several companies, including PayPal, SpaceX, Tesla, Neuralink, and The Boring Company.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  clear memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Memory has been cleared!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "def start_chatbot():\n",
    "    print(\"Hello! I am your assistant. You can start asking questions now.\\n(Type 'exit' to end the chat.)\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "            print(\"Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        result = chat_with_memory(user_input)\n",
    "        print(\"Bot:\", result)\n",
    "\n",
    "        # Display chat history\n",
    "        # print(\"Current Memory:\")\n",
    "        # print(buffer_memory.chat_memory.messages)\n",
    "\n",
    "# Run the chatbot\n",
    "start_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
